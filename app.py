import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from flask import Flask, request, jsonify
import threading
import time

# Configuration
MODEL_NAME = "gopu-poss/agent"
PORT = 4299

# Chargement du modÃ¨le
print("ğŸ”§ Chargement du modÃ¨le agentV1...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    device_map="auto"
)
print("âœ… ModÃ¨le agentV1 chargÃ©!")

app = Flask(__name__)

def generate_response(prompt, max_tokens=150, temperature=0.7):
    """GÃ©nÃ¨re une rÃ©ponse avec le modÃ¨le"""
    inputs = tokenizer(prompt, return_tensors="pt")
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            temperature=temperature,
            do_sample=True,
            top_p=0.9,
            repetition_penalty=1.1,
            pad_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    # Nettoyer la rÃ©ponse
    if prompt in response:
        response = response.replace(prompt, "").strip()
    return response

@app.route('/chat', methods=['POST'])
def chat():
    """Endpoint pour discuter avec le modÃ¨le"""
    data = request.json
    message = data.get('message', '')
    
    if not message:
        return jsonify({'error': 'Aucun message fourni'}), 400
    
    try:
        response = generate_response(message)
        return jsonify({
            'response': response,
            'model': 'agentV1',
            'developer': 'Mauricio Mangituka'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    """Endpoint de santÃ©"""
    return jsonify({'status': 'active', 'model': 'agentV1', 'port': PORT})

def terminal_chat():
    """Mode conversation terminal"""
    print("\n" + "="*50)
    print("ğŸ¤– agentV1 - Mode Terminal")
    print("DÃ©veloppÃ© par Mauricio Mangituka")
    print("Tapez 'quit' pour quitter")
    print("="*50)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ Vous: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ Au revoir!")
                break
            
            if not user_input:
                continue
                
            print("ğŸ¤– agentV1: ", end="", flush=True)
            response = generate_response(user_input)
            print(response)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ArrÃªt du programme...")
            break
        except Exception as e:
            print(f"\nâŒ Erreur: {e}")

def start_flask_server():
    """DÃ©marre le serveur Flask"""
    print(f"ğŸŒ DÃ©marrage du serveur sur le port {PORT}...")
    app.run(host='0.0.0.0', port=PORT, debug=False)

if __name__ == "__main__":
    print("ğŸš€ agentV1 - Service de Chat IA")
    print("Options:")
    print("1. Mode Terminal (tapez 'terminal')")
    print("2. Mode API (tapez 'api')")
    print("3. Les deux (tapez 'both')")
    
    choice = input("\nChoisissez le mode: ").strip().lower()
    
    if choice == 'terminal':
        terminal_chat()
    elif choice == 'api':
        start_flask_server()
    elif choice == 'both':
        # DÃ©marrer le serveur dans un thread sÃ©parÃ©
        server_thread = threading.Thread(target=start_flask_server, daemon=True)
        server_thread.start()
        print(f"âœ… Serveur API dÃ©marrÃ© sur http://localhost:{PORT}")
        time.sleep(2)
        terminal_chat()
    else:
        print("âŒ Choix invalide. Utilisation du mode terminal par dÃ©faut.")
        terminal_chat()
